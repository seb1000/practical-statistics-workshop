{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Statistic workshop\n",
    "#### one of the overarching questions in this workshop:\n",
    "## What does \"statistically significant\" actually mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from pylab import plt\n",
    "import pandas as pd\n",
    "sns.set_style(\"ticks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a sample from a normal distribution\n",
    "N = 10\n",
    "scale=1\n",
    "loc=0  # mean of the underlying distribution\n",
    "mysample = stats.norm.rvs(loc=loc,scale=scale,size=N)\n",
    "# now we compute the empirical mean of the distribution, thus the \n",
    "# mean computed from the sampel\n",
    "empirical_mean = np.mean(mysample)\n",
    "empirical_std = np.std(mysample)\n",
    "print(f'background mean:{loc}')\n",
    "print(f'background std:{scale}')\n",
    "print(f'empirical mean:{empirical_mean}')\n",
    "print(f'empirical std:{empirical_std}')\n",
    "\n",
    "plt.figure()\n",
    "sns.distplot(mysample)\n",
    "plt.axvline(empirical_mean)\n",
    "plt.title('N:'+str(N))\n",
    "plt.show()\n",
    "# rerun this cell (press ctrl-enter) a couple of times and see how the empirical mean changes.\n",
    "# note that we KNOW that the mean of the real distribution is 0!\n",
    "# try out also other values for N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we establish a concept that will be very important : the difference between the\n",
    "### Background Distribution\n",
    "and the \n",
    "### Empirical Distribution\n",
    "The empirical distribution is what we actually get from observations (observations are meant here in a broad sense, so the output of numerical models for example would also count as observataions). The background distribution is usually not known, but is what we want to estimate. In this workshop we use random number generators to generate empirical distributions, and we actually know the background distributions of these random number generators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# comparing the mean of 2 distributions\n",
    "Do two distributions have a different mean?\n",
    "Let's say we have 2 series of measurements from 2 different groups.\n",
    "Now what does it actually mean the the difference in the mean of the groups is \"statistically significant\"?\n",
    "We can explore this by again drawing smaples fro known distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1=20\n",
    "N2=N1\n",
    "# let's start with a case where the 2 distributions do actually have different means (defined via the loc parameter)\n",
    "# our null-hypothesis: mean1 > mean2\n",
    "loc1=0\n",
    "loc2=0\n",
    "scale1=1\n",
    "scale2=1\n",
    "# draw one samle of size N1 from each background distribution\n",
    "sample1=stats.norm.rvs(loc=loc1,scale=scale1,size=N1)\n",
    "sample2=stats.norm.rvs(loc=loc2,scale=scale2,size=N2)\n",
    "\n",
    "# compute the mean of each sample\n",
    "emp_mean1=np.mean(sample1)\n",
    "emp_mean2=np.mean(sample2)\n",
    "\n",
    "# plot both distributions and their means\n",
    "colors=['#1b9e77', '#d95f02', '#7570b3']\n",
    "plt.figure()\n",
    "sns.distplot(sample1, label='sample1', color=colors[0])\n",
    "sns.distplot(sample2, label='sample2', color=colors[1])\n",
    "plt.axvline(emp_mean1, color=colors[0])\n",
    "plt.axvline(emp_mean2, color=colors[1])\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## again, rerun this a couple of times, and try out other values for loc2\n",
    "## also try out other values of N. You will find that sometimes the epmirical mean of the distribution\n",
    "## with greater mean will be smaller than the empirical mean of the distribution with the smaller mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now we do the same thing, but a lot of times (1000) times:\n",
    "# each time, we draw a sample of N from the 2 background-distributions, and compute\n",
    "# the empirical mean of the samples\n",
    "loc1=0\n",
    "loc2=0.2\n",
    "N_iter=1000\n",
    "N=1000\n",
    "means1=[]\n",
    "means2=[]\n",
    "for i in range(N_iter):\n",
    "    sample1=stats.norm.rvs(loc=loc1,scale=scale1,size=N1)\n",
    "    sample2=stats.norm.rvs(loc=loc2,scale=scale2,size=N2)\n",
    "    means1.append(np.mean(sample1))\n",
    "    means2.append(np.mean(sample2))\n",
    "    \n",
    "means1=np.array(means1)    \n",
    "means2=np.array(means2)\n",
    "diff = means1-means2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we plot a histogram of the differenc of the means (so for every iteration N_iter, we compute the difference\n",
    "# between the empirical mean of sample1 and sample 2)\n",
    "plt.figure()\n",
    "sns.distplot(diff)\n",
    "plt.axvline(0, color='black')\n",
    "plt.xlabel('emp_mean(samaple1) - emp_mean(samaple2)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we know that the underlying distributions of our 2 groups have different mean, and that mean2 > mean1 (we specified this!), but still we now see that in some cases, when drawing two samples of size N from the underlying the distributions, it appreas to be different:\n",
    "for the empirical means, sometimes mean2 < mean1 ! \n",
    "This is the problem of empirical means: they are uncertain!\n",
    "now a statement \"mean2>mean1 with a significance of 0.95\" actually means: if in reality mean2 < mean1, then only 5 % of realisations would show mean2 > mean1 here, we can approach this \"from the other side\", since we can generate random realisations at our will, and we can count how the percentage of \"wrong\" outcomes is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_mean1_st_mean2 = len(diff[diff>0])/len(diff)\n",
    "print(perc_mean1_st_mean2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is now the fraction of cases where - given the background-distributions that we specified- by chance you would get a false result if you increase N1 and N2, this number will decrease (try it out!). Sideremark: this fraction will change slightly if you run the script again - this the uncertainty by the finit sampling of realistations (N_iter). The bigger N_iter, the less perc_mean1_st_mean2 will change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2-variable dataset that has correlation \"build-in\"\n",
    "x = stats.norm.rvs(size=100)\n",
    "alpha=0.9\n",
    "y = x + alpha*stats.norm.rvs(size=100)\n",
    "plt.figure()\n",
    "sns.jointplot(x,y, kind='reg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 2-variable dataset that has no correlation (x and y are independent random variables)\n",
    "N=100\n",
    "x = stats.norm.rvs(size=N)\n",
    "y = stats.norm.rvs(size=N)\n",
    "plt.figure()\n",
    "sns.jointplot(x,y, kind='reg')\n",
    "# the blue shading shows the 5-95 confidence interval for the regression. If the shading does not cross the zero-line,\n",
    "# then this means there is correlation with signifiance of 0.9\n",
    "# if you run this cell often enough, you find something interesting: from time to time \n",
    "# (the smaller N, the more often this will happen), there will be significant\n",
    "# correlation. Even though we know that the background-distributions are uncorrelated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's automatize this. We draw random samples x and y, and compute the correlation\n",
    "# for this we use a bootstrapping function. We will come back to bootstrapping later, for now just\n",
    "# accept that the function below returns the confidence interval of the correlation of its inputs\n",
    "# x and y.\n",
    "perc = 5 # 2-sided confidence interval (5 means 5-95)\n",
    "def bootstrapped_correlation(x,y,perc=perc, N=1000):\n",
    "    assert(len(x)==len(y))\n",
    "    corrs = []\n",
    "    for i in range(N):\n",
    "        indices = np.random.choice(len(x), replace=True, size=len(x))\n",
    "        corr = np.corrcoef(x[indices], y[indices])[0,1]\n",
    "        corrs.append(corr)\n",
    "    corrs=np.array(corrs) \n",
    "    #corrs = sns.algorithms.bootstrap(x,y,func=lambda x,y:np.corrcoef(x,y)[0,1])\n",
    "    meancorr = np.corrcoef(x,y)[0,1]\n",
    "    upper = np.percentile(corrs,q=100-perc)\n",
    "    lower = np.percentile(corrs,q=perc)\n",
    "    \n",
    "    return meancorr,lower,upper\n",
    "\n",
    "N_iter = 1000\n",
    "res = []\n",
    "for i in range(N_iter):\n",
    "    x = stats.norm.rvs(size=N)\n",
    "    y = stats.norm.rvs(size=N)\n",
    "    meancorr,lower,upper = bootstrapped_correlation(x,y)\n",
    "    # if both the upper and the lower are below zero, or both are above zero\n",
    "    # then we have significant correlation\n",
    "    is_significant = np.sign(upper) == np.sign(lower)\n",
    "    res.append(is_significant)\n",
    "res = np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the fraction of cases where we found spurious correlation\n",
    "fraction_spurios_correlation = np.mean(res)\n",
    "print(fraction_spurios_correlation)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this number mean? Try out different values for \"perc\" above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Highly-dimensional datasets\n",
    "\n",
    "The above mentioned issues (that a random process will yield significant correlation/difference/etc from time to time, has very important implications when analyzing high dimensional datasets.\n",
    "Here, \"dimensional\" is very general, and does not only relate to space or time dimensions. It can also mean many different variables. For example, if you have spatial data at 10x10 gridpoints, you have 10x10=100 variables, and thus the dimensionality of the data is not 2 but 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create some random data\n",
    "# assume that we have\n",
    "Ndim = 10\n",
    "# different variables, all random and uncorrelated, and for each variable we have\n",
    "N= 100\n",
    "# observations\n",
    "df = pd.DataFrame(np.random.random((N,Ndim)))\n",
    "\n",
    "# nowmake a matrix plot with bootstrapped correlation\n",
    "plt.figure()\n",
    "sns.pairplot(df, kind='reg')\n",
    "#this command can take a while\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## can you find pairs that have significant correltaion?\n",
    "## what does that mean?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now compute the signifianc for every pair\n",
    "res_is_sig = []\n",
    "for i in range(Ndim):\n",
    "    print(i)\n",
    "    for j in range(Ndim):\n",
    "        if i != j:\n",
    "            meancorr,lower,upper = bootstrapped_correlation(df[i], df[j],\n",
    "                                                            perc=5,\n",
    "                                                            N=100) # we use only 100 bootstraps to speed things up\n",
    "            is_significant = np.sign(upper) == np.sign(lower)\n",
    "            res_is_sig.append(is_significant)\n",
    "            \n",
    "\n",
    "print('fraction of significant pairs:',np.mean(res_is_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to automatize this process, and \"mine\" for correlations in the data. This is what we often do in \n",
    "exploratory data analysis. Hoever, this approach is potentially *fundamentally flawed*. The approach of using p-values for deciding on significance is only valid if you *first* set up a hypothesis - ideally based on prior knowledge, physical intuition etc, and afterwards* test in on data. The p-value is then the probability that a random process yields your result.\n",
    "If you simply mine your data, you arbitrarily set up hypothesis and test them.\n",
    "### Q: how do we approach this in our field of science?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### another example: difference between maps showing time-mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "Nx = 10\n",
    "Ny = 20\n",
    "data3d1 = np.random.random((N,Nx,Ny))\n",
    "data3d2 = np.random.random((N,Nx,Ny))\n",
    "# compute time mean\n",
    "mean1 = np.mean(data3d1, axis=0)\n",
    "mean2 = np.mean(data3d2, axis=0)\n",
    "plt.figure()\n",
    "plt.imshow(mean1-mean2, cmap=plt.cm.RdBu); plt.colorbar()\n",
    "plt.title('diff')\n",
    "\n",
    "\n",
    "# is the difference in the mean significant?\n",
    "# since we have normal data, we use a t-test here instead of bootstrapping (for speed)\n",
    "p = 0.95\n",
    "is_sig = np.zeros((Nx,Ny))\n",
    "for i in range(Nx):\n",
    "    for j in range(Ny):\n",
    "        \n",
    "        _, pfromtest = stats.ttest_ind(data3d1[:,i,j], data3d2[:,i,j])\n",
    "        if pfromtest > p :\n",
    "            is_sig[i,j] = 1\n",
    "        else:\n",
    "            is_sig[i,j] = 0\n",
    "\n",
    "            \n",
    "plt.figure()\n",
    "plt.imshow(is_sig)\n",
    "plt.title('significant points')\n",
    "plt.colorbar()\n",
    "# now compute the area that passed the test\n",
    "sig_area_fraction = np.sum(is_sig) / (Nx*Ny)\n",
    "print(f'significant area fraction: {sig_area_fraction} for p={p} (alpha={1-p})')\n",
    "\n",
    "## rerun this a couple of times,(also try out different p-vals). What is the fraction is significant points\n",
    "## you get on average?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now we know how much \"spurios\" points we can expect. Now how to deal with this?\n",
    "### any ideas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Computing confidence intervals for (nearly) whatever type of data/plot\n",
    "# Bootstrapping\n",
    "Up to now, we used the bootstrapping function (and the bootstrapping built into seaborn) as a black-box. you simply had to believe that it made sense.\n",
    "Here we will discuss why this is actually the case\n",
    "\n",
    "The principle goal behind bootstrapping is to get the *uncertainty of an empirical distribution*, given the empirical distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets say we have the following data (e.g. from an experiment)\n",
    "expdata = np.array([0.07047472, 3.33453415, 0.05658453, 2.4356657 , 0.70741267,\n",
    "       1.04390018, 1.1783881 , 0.18144047, 0.46671969, 0.07755574,\n",
    "       0.21910896, 0.03822302, 0.16925173, 0.84388231, 1.18402365,\n",
    "       4.15818062, 0.24154752, 2.16320588, 2.8907313 , 0.16688633,\n",
    "       1.16460308, 1.17720384, 0.32996651, 0.16892912, 0.77367657,\n",
    "       3.35677442, 0.14811093, 3.99420697, 0.62633901, 0.98861266])\n",
    "\n",
    "N = len(expdata)\n",
    "# we can plot the distribution of the empirical data\n",
    "sns.distplot(expdata)\n",
    "plt.axvline(np.mean(expdata))\n",
    "# cleary, the data is not normally distributed, and we do not know how it is distributed for example, \n",
    "# rainfall data might look similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# however, how certain are we that this distribution really reflects the background distribution\n",
    "# of the data?\n",
    "# this is very similar to the very beginning of this workshop, were we created empirical distributions\n",
    "#from a known distribution.\n",
    "# to get a feeling about how uncertatin the empirical distribution, we simple reran the random generator a couple \n",
    "# of times.\n",
    "# However, here we cannot do this - this would mean repeating the experiment. But is there a way to get an \n",
    "# idea of the uncertainty in the empirical distrubiton without running addidionatl experiments, thus only\n",
    "# from the data?\n",
    "# the solution is to run \"fake\"-experiments. Instead of generating real new distributions (what we would do\n",
    "# in an experiment, we generate new distributions from the data we already have)\n",
    "# this we do via randomly drawing with replacing.\n",
    "# if we have N samples, we draw N individual samples, putting back the one we drew (so in the end\n",
    "# we can draw a specific sample multiple times)\n",
    "# this can be done with the random.choice function\n",
    "newdata = np.random.choice(expdata, size=N, replace=True)\n",
    "sns.distplot(newdata)\n",
    "plt.axvline(np.mean(newdata))\n",
    "# run this a couple of times, and compare it with the plot of the original expdata above\n",
    "print(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The changes from repetition to repitition indicate the uncertaint, including the position of the mean (vertical\n",
    "# line)\n",
    "# now we will quantify this\n",
    "N_boot = 100\n",
    "res = []\n",
    "for _ in range(N_boot):\n",
    "    newdata = np.random.choice(expdata, size=N, replace=True)\n",
    "    res.append(newdata)\n",
    "    \n",
    "# now we have a 2d array res (N_boot,N), and each row contains one realization of the random drawing\n",
    "# from the expdata\n",
    "# now we compute a histogram for every realization\n",
    "bins = np.arange(0,10,2)\n",
    "hists = np.array([np.histogram(row, bins=bins)[0] for row in res])\n",
    "boot_median = np.median(hists,axis=0)\n",
    "boot_upper = np.percentile(hists,q=95,axis=0)\n",
    "boot_lower = np.percentile(hists,q=5,axis=0)\n",
    "# note that here median is NOT the median of the empirical distribution, but it is the median\n",
    "# over the bootstraps, computed individually for each histogram bin\n",
    "\n",
    "bin_centers = (bins[1:] + bins[:-1])/2 # necessary for plotting\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(bin_centers,boot_median, label='boot_median')\n",
    "plt.fill_between(bin_centers,boot_lower,boot_upper, label='boot_median', alpha=0.5)\n",
    "\n",
    "# we can also make a boxplot\n",
    "plt.figure()\n",
    "_ = plt.boxplot(hists,labels=bin_centers)  # the _= is necessary to suppress output in the notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## and voila: now we have an estimate of the uncertainty of our distribution!\n",
    "now can take this one step further, and extend it to any measure of our distribution (e.g. mean, median, but also more complicated like the RMSE of data etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute uncertainty of the mean of the distribution\n",
    "N_boot = 100\n",
    "means = []\n",
    "for _ in range(N_boot):\n",
    "    newdata = np.random.choice(expdata, size=N, replace=True)\n",
    "    mean_of_this_sample = np.mean(newdata)\n",
    "    means.append(mean_of_this_sample)\n",
    "    \n",
    "sns.distplot(means)\n",
    "mean_of_means = np.mean(means)\n",
    "upper = np.percentile(means,q=95)\n",
    "lower = np.percentile(means,q=5)\n",
    "print(f'mean of mean:{mean_of_means:.2f}, confidence interval: {lower:.2f}-{upper:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PYTHON-SPECIFIC\n",
    "## generalizing this to arbitary estimatros is easy in python:\n",
    "\n",
    "\n",
    "\n",
    "def bootstrapped_ci(data, estimator, ci=95, N=1000):\n",
    "    \"\"\"\n",
    "    compute a confidence interval over data using estimator with bootstrapping\n",
    "    :param data: input data\n",
    "    :param estimator: callable, function that returns a single scalar value (e.g. np.mean)\n",
    "    :param ci: float, [0-100]\n",
    "    :param N: number of bootstrapts\n",
    "    :return: mean, lower, upper\n",
    "    \"\"\"\n",
    "\n",
    "    res = []\n",
    "    for i in range(N):\n",
    "        newdata = np.random.choice(data, size=N, replace=True)\n",
    "        # apply function\n",
    "        estimated = estimator(newdata)\n",
    "        res.append(estimated)\n",
    "    res = np.array(res)\n",
    "    mmean = np.mean(res)\n",
    "    upper = np.percentile(res, q=100 - (100 - ci)/2)\n",
    "    lower = np.percentile(res, q=(100-ci)/2)\n",
    "\n",
    "    return mmean, lower, upper\n",
    "\n",
    "\n",
    "\n",
    "# example: using np.mean\n",
    "mmean, lower, upper = bootstrapped_ci(expdata, estimator=np.mean, ci=95)\n",
    "print(f'mean of mean:{mmean:.2f}, confidence interval: {lower:.2f}-{upper:.2f}')\n",
    "\n",
    "# example: using np.meadian\n",
    "mmedian, lower, upper = bootstrapped_ci(expdata, estimator=np.median, ci=95)\n",
    "print(f'mean of median:{mmedian:.2f}, confidence interval: {lower:.2f}-{upper:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for correlation it is a bit more tricky, because correlation is a 2-variable estimator\n",
    "# here, we cannot independently make new distributions from the dataset, but we always must choose pairs\n",
    "\n",
    "\n",
    "# this is what the mysterious functio nwe used earlier does:\n",
    "def bootstrapped_correlation(x,y,perc=5,N=1000):\n",
    "    assert(len(x)==len(y))\n",
    "    corrs = []\n",
    "    for i in range(N):\n",
    "        indices = np.random.choice(len(x), replace=True, size=len(x))\n",
    "        corr = np.corrcoef(x[indices], y[indices])[0,1] # np.coorcoef returns a correlation matrix, extract [0,1]\n",
    "        corrs.append(corr)\n",
    "    corrs=np.array(corrs) \n",
    "    meancorr = np.corrcoef(x,y)[0,1]\n",
    "    upper = np.percentile(corrs,q=100-perc)\n",
    "    lower = np.percentile(corrs,q=perc)\n",
    "    \n",
    "    return meancorr,lower,upper\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bootstrapping built into seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load some example data\n",
    "iris = sns.load_dataset('iris')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.barplot('species','sepal_length',  data=iris)\n",
    "# if not specified otherwise, nearly all seaborn plots automatically include uncertainty estimates of the mean (ci=95)\n",
    "# if we plot \"species\" vs \"sepal_length\", then for each species, the mean is computed over all samples, and\n",
    "# plotted as a bar. additionally, the uncertainty in this mean is plotted as small bars\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if you do not want the mean, but another estimator, you can explicitely pass an estimarot\n",
    "sns.barplot('species','sepal_length',  data=iris, estimator=np.median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# timeseris\n",
    "fmri = sns.load_dataset(\"fmri\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fmri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=\"timepoint\", y=\"signal\",  hue=\"event\", style=\"event\", data=fmri)\n",
    "sns.despine()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
